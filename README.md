# watermarking 

## Introduction
Large language models (LLMs) have revolutionized natural language processing, enabling them to perform a wide range of tasks, from writing documents to generating executable code and answering complex questions with astonishing human-like proficiency.

Considering these concerns, we focus our efforts in this repository on analyzing the paper [<b>A Watermark for Large Language Models</b>](https://arxiv.org/abs/2301.10226) and studying watermarking effect on the summarization task by using a language model. Through the implementation of this innovative algorithm, our objective is to effectively identify machine-generated text and prevent the potentially harmful effects of language models. 